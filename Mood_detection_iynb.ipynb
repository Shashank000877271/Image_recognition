{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0z43JSZ3bBq"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/nilt43hyl1dx82k/dataset.zip?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip?dl=0"
      ],
      "metadata": {
        "id": "2_OxkW854K0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Pillow"
      ],
      "metadata": {
        "id": "lY0uhcDCCFkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check Pillow version number\n",
        "import PIL\n",
        "print('Pillow Version:', PIL.__version__)"
      ],
      "metadata": {
        "id": "dzsAA5udCKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and show an image with Pillow\n",
        "from PIL import Image\n",
        "# Open the image form working directory\n",
        "image = Image.open('D:\\music\\Emotion-detection-main\\dataset.zip\\train\\angry\\Training_3908.jpg')\n",
        "# summarize some details about the image\n",
        "print(image.format)\n",
        "print(image.size)\n",
        "print(image.mode)\n",
        "# show the image\n",
        "load_image.show()"
      ],
      "metadata": {
        "id": "vCopy996CRk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "id": "SeZXpASR4mNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "metadata": {
        "id": "Jh1WuSDU4z3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "id": "iRSGNwNX5Ywu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "id": "9CHMjNhC5gB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "id": "u12DYObb5kth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input \n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.preprocessing import image\n",
        "from keras_preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "pO3_-8gM4NG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with pre trained model \n",
        "\n",
        "base_model = MobileNet( input_shape=(224,224,3), include_top= False )\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(units=7 , activation='softmax' )(x)\n",
        "\n",
        "# creating our model.\n",
        "model = Model(base_model.input, x)"
      ],
      "metadata": {
        "id": "uikXtq0U4VkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= categorical_crossentropy , metrics=['accuracy']  )"
      ],
      "metadata": {
        "id": "6N-iNbDS627e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "     zoom_range = 0.2, \n",
        "     shear_range = 0.2, \n",
        "     horizontal_flip=True, \n",
        "     rescale = 1./255\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory= \"/content/train\", \n",
        "                                               target_size=(224,224), \n",
        "                                               batch_size=32,\n",
        "                                  )\n",
        "\n",
        "\n",
        "train_data.class_indices"
      ],
      "metadata": {
        "id": "iFZHglhx7ZUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(rescale = 1./255 )\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(directory= \"/content/test\", \n",
        "                                           target_size=(224,224), \n",
        "                                           batch_size=32,\n",
        "                                  )"
      ],
      "metadata": {
        "id": "Uc-fTltu7cV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to visualize the images in the traing data denerator \n",
        "\n",
        "t_img , label = train_data.next()\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# function when called will prot the images \n",
        "def plotImages(img_arr, label):\n",
        "  \"\"\"\n",
        "  input  :- images array \n",
        "  output :- plots the images \n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  for im, l in zip(img_arr,label) :\n",
        "    plt.imshow(im)\n",
        "    plt.title(im.shape)\n",
        "    plt.axis = False\n",
        "    plt.show()\n",
        "    \n",
        "    count += 1\n",
        "    if count == 10:\n",
        "      break\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# function call to plot the images \n",
        "plotImages(t_img, label)"
      ],
      "metadata": {
        "id": "kVzD4fN_7ffU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## having early stopping and model check point \n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
        "\n",
        "# model check point\n",
        "mc = ModelCheckpoint(filepath=\"best_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
        "\n",
        "# puting call back in a list \n",
        "call_back = [es, mc]"
      ],
      "metadata": {
        "id": "Hj-7j10N7iCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit_generator(train_data, \n",
        "                           steps_per_epoch= 10, \n",
        "                           epochs= 30, \n",
        "                           validation_data= val_data, \n",
        "                           validation_steps= 8, \n",
        "                           callbacks=[es,mc])"
      ],
      "metadata": {
        "id": "ClfTbQBX7lyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading the best fit model \n",
        "from keras.models import load_model\n",
        "model = load_model(\"/content/best_model.h5\")"
      ],
      "metadata": {
        "id": "TkWQ8ypU7nzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h =  hist.history\n",
        "h.keys()"
      ],
      "metadata": {
        "id": "imMSgGYr7sRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['accuracy'])\n",
        "plt.plot(h['val_accuracy'] , c = \"red\")\n",
        "plt.title(\"acc vs v-acc\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WoVfv14W9x7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['loss'])\n",
        "plt.plot(h['val_loss'] , c = \"red\")\n",
        "plt.title(\"loss vs v-loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mADJL8Ne90V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just to map o/p values \n",
        "op = dict(zip( train_data.class_indices.values(), train_data.class_indices.keys()))"
      ],
      "metadata": {
        "id": "OYNsQf1U9597"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.preprocessing import image\n",
        "from keras_preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "ndwIqGS9GdOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path for the image to see if it predics correct class\n",
        "\n",
        "path = \"/content/test/neutral/PrivateTest_698548.jpg\"\n",
        "img = load_img(path, target_size=(224,224) )\n",
        "\n",
        "i = img_to_array(img)/255\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(f\" the image is of {op[pred]}\")\n",
        "\n",
        "# to display the image  \n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BrNTT1hv99m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n"
      ],
      "metadata": {
        "id": "x3PeIaEl-Rfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path for the image to see if it predics correct class\n",
        "\n",
        "path = \"/content/test/sad/PrivateTest_2311869.jpg\"\n",
        "img = load_img(path, target_size=(224,224) )\n",
        "\n",
        "i = img_to_array(img)/255\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(f\" the image is of {op[pred]}\")\n",
        "\n",
        "# to display the image  \n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LfvG35rHAfOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/test/neutral/PrivateTest_4361041.jpg\"\n",
        "img = load_img(path, target_size=(224,224) )\n",
        "\n",
        "i = img_to_array(img)/255\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(f\" the image is of {op[pred]}\")\n",
        "\n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XnynuVJ9MDWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path for the image to see if it predics correct class\n",
        "\n",
        "path = \"/content/test/disgust/PrivateTest_3838250.jpg\"\n",
        "img = load_img(path, target_size=(224,224) )\n",
        "\n",
        "i = img_to_array(img)/255\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(f\" the image is of {op[pred]}\")\n",
        "\n",
        "# to display the image  \n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l4-5bM0-MO-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcRJyQgmM-jH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}